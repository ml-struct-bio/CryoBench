{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b853e6ea-5030-45ca-ab6b-1f42445bf374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(INFO) (xla_bridge.py) (19-Feb-24 13:03:04) Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA\n",
      "(INFO) (xla_bridge.py) (19-Feb-24 13:03:04) Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "(INFO) (config.py) (19-Feb-24 13:03:04) Devices found: NVIDIA A100-SXM4-80GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 13:03:14.029337: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-19 13:03:14.029421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-19 13:03:14.049566: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-19 13:03:16.256145: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) Image size (pix)  : 128\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) A/pix             : 3.0\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) DefocusU (A)      : 19267.099609375\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) DefocusV (A)      : 19048.19921875\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) Dfang (deg)       : 77.30999755859375\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) voltage (kV)      : 300.0\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) cs (mm)           : 2.700000047683716\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) w                 : 0.07000000029802322\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) Phase shift (deg) : 0.0\n",
      "n images 10000\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) Image size (pix)  : 128\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) A/pix             : 3.0\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) DefocusU (A)      : 19267.099609375\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) DefocusV (A)      : 19048.19921875\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) Dfang (deg)       : 77.30999755859375\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) voltage (kV)      : 300.0\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) cs (mm)           : 2.700000047683716\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) w                 : 0.07000000029802322\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:19) Phase shift (deg) : 0.0\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:20) Image size (pix)  : 128\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:20) A/pix             : 3.0\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:20) DefocusU (A)      : 19267.099609375\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:20) DefocusV (A)      : 19048.19921875\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:20) Dfang (deg)       : 77.30999755859375\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:20) voltage (kV)      : 300.0\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:20) cs (mm)           : 2.700000047683716\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:20) w                 : 0.07000000029802322\n",
      "(INFO) (ctf.py) (19-Feb-24 13:03:20) Phase shift (deg) : 0.0\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import recovar.config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import subprocess\n",
    "import os, sys\n",
    "\n",
    "from cryodrgn import analysis\n",
    "from cryodrgn import utils\n",
    "# from cryodrgn import dataset\n",
    "from cryodrgn import ctf\n",
    "from recovar import plot_utils\n",
    "from recovar import output, dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from ipywidgets import interact, interactive, HBox, VBox\n",
    "from scipy.spatial.transform import Rotation as RR\n",
    "# py.init_notebook_mode()\n",
    "from IPython.display import FileLink, FileLinks\n",
    "import jax.numpy as jnp\n",
    "from recovar.fourier_transform_utils import fourier_transform_utils\n",
    "from recovar import core\n",
    "ftu = fourier_transform_utils(jnp)\n",
    "\n",
    "grid_size =256//2\n",
    "log_n = 4\n",
    "output_folder = f\"/home/mg6942/mytigress/spike{grid_size}_new{log_n}/\"\n",
    "# output_folder = f\"/home/mg6942/mytigress/spike{grid_size}_new3/\"\n",
    "# output_folder ='/home/mg6942/mytigress/spike256/../'\n",
    "volume_folder_input =  f\"/home/mg6942/mytigress/spike{grid_size}/\"\n",
    "outlier_file_input = \"/home/mg6942/mytigress/simulated_empiar10180/volumes/vol0915.mrc\"\n",
    "dataset_dict = dataset.get_default_dataset_option()\n",
    "\n",
    "# Fill these options with the path to preprocessed files\n",
    "experiment_directory = '/home/mg6942/mytigress/uniform/'\n",
    "dataset_dict['ctf_file'] = output_folder + \"ctf.pkl\"\n",
    "dataset_dict['poses_file'] = output_folder + \"poses.pkl\"\n",
    "dataset_dict['particles_file'] = f\"{output_folder}particles.{grid_size}.mrcs\"\n",
    "\n",
    "# Returns an object that knows everything about the dataset.\n",
    "cryo_dataset = dataset.load_dataset_from_dict(dataset_dict, lazy = False)\n",
    "print(\"n images\", cryo_dataset.n_images)\n",
    "del dataset_dict['ind']\n",
    "cryos = dataset.get_split_datasets_from_dict(dataset_dict, dataset.split_index_list(np.arange(cryo_dataset.n_images)))\n",
    "\n",
    "# cryo = dataset.load_cryodrgn_dataset( f\"{output_folder}particles.{grid_size}.mrcs\", output_folder + \"poses.pkl\", output_folder + \"ctf.pkl\", lazy = False)\n",
    "from recovar import regularization, synthetic_dataset, noise, homogeneous, utils, adaptive_kernel_discretization\n",
    "sim_info = recovar.utils.pickle_load(output_folder + '/simulation_info.pkl')\n",
    "gt_recon = synthetic_dataset.load_heterogeneous_reconstruction(sim_info, volumes_path_root = None)\n",
    "gt_vol =gt_recon.get_mean()\n",
    "noise_variance = sim_info['noise_variance']\n",
    "HH = synthetic_dataset.load_heterogeneous_reconstruction(sim_info, volumes_path_root = None)\n",
    "gt_mean = HH.get_mean()\n",
    "signal_variance = utils.make_radial_image(regularization.average_over_shells(np.abs(gt_mean)**2, HH.volume_shape), HH.volume_shape)\n",
    "\n",
    "downsampled_mean = gt_mean * cryos[0].get_valid_frequency_indices(rad = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77750127-58cc-42c9-8f09-322da3ccbf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "import numpy as np\n",
    "NSIDE = 2**1\n",
    "nside = NSIDE\n",
    "m = hp.nside2npix(NSIDE)\n",
    "\n",
    "z = hp.pix2ang(nside, np.arange(m))\n",
    "\n",
    "angle_res = hp.nside2resol(nside, arcmin=True) / 60 \n",
    "n_in_planes = np.round(360 / angle_res).astype(int)\n",
    "in_angle_angles = np.linspace(0, 2 * np.pi, n_in_planes)\n",
    "\n",
    "angles = np.meshgrid( np.arange(m), in_angle_angles )\n",
    "theta = z[0][angles[0]]\n",
    "phi = z[1][angles[0]]\n",
    "angles = np.stack( [theta, phi, angles[1] ], axis=-1)\n",
    "angles = angles.reshape( -1, 3)\n",
    "\n",
    "from cryodrgn import utils as cryodrgn_utils\n",
    "rotation_matrices = np.array([cryodrgn_utils.R_from_relion(*angle) for angle in angles])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa39ba-03a1-4ed8-b45b-56784e847c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_1613347/1110154443.py\u001b[0m(61)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     59 \u001b[0;31m\u001b[0mtranslation_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m\u001b[0mnorm_res_squared_l\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 61 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     62 \u001b[0;31m    \u001b[0;31m# Only place where image mask is used ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     63 \u001b[0;31m    \u001b[0;31m# print('TOOK OUT IMAGE MASK IN MEAN!!! PUT IT BACK??')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "reload(core)\n",
    "import jax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "# TODO: Should it be residual of masked?\n",
    "# Residual will be 4 dimensional\n",
    "# volumes_batch x images_batch x pose_batch  \n",
    "# @functools.partial(jax.jit, static_argnums = [7,8,9,10,11,12])    \n",
    "def compute_residuals_many_poses(volumes, images, rotation_matrices, translations, CTF_params, noise_variance, voxel_size, volume_shape, image_shape, grid_size, disc_type, CTF_fun ):\n",
    "    # Rotations should be vol_batch x images_batch x rotation_batch x 10\n",
    "    # assert(rotation_matrices.shape[0] == volumes.shape[0])\n",
    "    # assert((translations.shape[:-1] == rotation_batch.shape[0]).all())\n",
    "    # assert(rotation_matrices.shape[1] == images.shape[0])\n",
    "    # assert(translations.shape[0] == volumes.shape[0])\n",
    "    # assert(translations.shape[1] == images.shape[0])\n",
    "\n",
    "    # n_vols x rotations x image_size\n",
    "    projected_volumes = core.batch_vol_rot_slice_volume_by_map(volumes, rotation_matrices, image_shape, volume_shape, disc_type)\n",
    "    # Broadcast CTF in volumes x rotations\n",
    "    projected_volumes = (projected_volumes * CTF_fun( CTF_params, image_shape, voxel_size)[None,:,None,:])[...,None,:]\n",
    "\n",
    "    # How should translations be fixed ? hmmm\n",
    "    # Broacast over volumes x rotations\n",
    "    translated_images = core.batch_trans_translate_images(images, translations, image_shape)[None,:, None]\n",
    "    \n",
    "    norm_res_squared = jnp.linalg.norm((projected_volumes - translated_images) / jnp.sqrt(noise_variance), axis = (-1))**2\n",
    "\n",
    "    # Output is vol_batch x image_batch x rots_batch x trans_batch\n",
    "    return norm_res_squared\n",
    "\n",
    "\n",
    "def compute_probability_from_residual_normal_squared_one_image(norm_res_squared):\n",
    "    exp_res = jnp.exp(- norm_res_squared)\n",
    "    summed_exp = jnp.sum(exp_res)\n",
    "    return exp_res / summed_exp\n",
    "\n",
    "compute_probability_from_residual_normal_squared = jax.vmap(compute_probability_from_residual_normal_squared_one_image)\n",
    "\n",
    "def compute_adj_slice(one_image, rotation_matrices, translations, CTF_params, probabilities):\n",
    "    CTF = CTF_fun( CTF_params, image_shape, voxel_size)\n",
    "    one_image_summed  = jnp.sum(batch_translate(one_image * CTF * probabilities, translations))\n",
    "    indices = core.get_nearest_gridpoint_indices(rotation_matrix, image_shape, volume_shape, grid_size)\n",
    "    volume = core.summed_adjoint_slice_by_nearest(volume_size, one_image_summed, indices)\n",
    "    return volume\n",
    "\n",
    "\n",
    "cryo = cryos[0]\n",
    "volumes = gt_mean\n",
    "\n",
    "noise_variance_rad = noise.make_radial_noise(noise_variance, cryo.image_shape)\n",
    "batch_size = 10\n",
    "experiment_dataset = cryo\n",
    "data_generator = experiment_dataset.get_dataset_generator(batch_size=batch_size) \n",
    "disc_type = 'nearest'\n",
    "\n",
    "rotation_grid = rotation_matrices\n",
    "translation_grid = (np.ones((5,2)) * 0 )\n",
    "norm_res_squared_l =  []\n",
    "for batch, indices in data_generator:\n",
    "    # Only place where image mask is used ?\n",
    "    # print('TOOK OUT IMAGE MASK IN MEAN!!! PUT IT BACK??')\n",
    "    all_rotations = np.repeat(rotation_grid[None], axis=0, repeats = indices.size)[None]\n",
    "    all_translations = np.repeat(translation_grid[None], axis=0, repeats = indices.size)\n",
    "    batch = experiment_dataset.image_stack.process_images(batch, apply_image_mask = False)\n",
    "    norm_res_squared = compute_residuals_many_poses(volumes[None],batch,\n",
    "                                                      all_rotations,\n",
    "                                                      all_translations,\n",
    "                                                    cryo.CTF_params[indices],\n",
    "                                                      noise_variance_rad, cryo.voxel_size,\n",
    "                                                      cryo.volume_shape, cryo.image_shape,\n",
    "                                                      cryo.grid_size, disc_type, cryo.CTF_fun )\n",
    "    \n",
    "    \n",
    "    probs = compute_probability_from_residual_normal_squared(norm_res_squared)\n",
    "    norm_res_squared_l.append(norm_res_squared)\n",
    "    import pdb; pdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17842fcb-ef70-42dc-a82c-9c6a51d6a327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm_res_squared_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a48bc-fe48-483d-b9c9-0a3aecd05af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_res_squared_l = jnp.concatenate(norm_res_squared_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a7d72-9a38-421f-8ec2-0d0408e17fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_res_squared_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22883306-156f-45c1-aec7-aa71d6e34c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04566b7-4623-4e39-a219-f2ec80563921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryodrgn import utils as cryodrgn_utils\n",
    "rotation_matrices = np.array([cryodrgn_utils.R_from_relion(*angle) for angle in angles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4f170-9664-49ad-b82b-05c5764d12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryodrgn import rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56999bc-732d-416d-8ca5-6c26c285462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = z[0][angles[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6700ad-495f-488f-91ec-2019e51c6535",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_angle_angles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69b84a-536e-41ef-8789-dbb1f7948a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter3("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5645db5-78c2-4a50-aa07-acf5bd8e3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f62df-b01f-4865-8d17-14dbd738a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recovar.config\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "from cryodrgn import analysis\n",
    "from cryodrgn import utils\n",
    "from cryodrgn import ctf\n",
    "from recovar import plot_utils\n",
    "from recovar import output, dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from recovar import simulator\n",
    "reload(simulator)\n",
    "import jax\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"error\")\n",
    "grid_size =128*1\n",
    "output_folder = f\"/home/mg6942/mytigress/spike{grid_size}_new/\"\n",
    "# output_folder ='/home/mg6942/mytigress/spike256/../'\n",
    "volume_folder_input =  f\"/home/mg6942/mytigress/spike{grid_size}/\"\n",
    "# volume_folder_input = f\"/home/mg6942/mytigress/constant_vol/\"\n",
    "\n",
    "outlier_file_input = \"/home/mg6942/mytigress/simulated_empiar10180/volumes/vol0915.mrc\"\n",
    "n_images = int(1e2)\n",
    "voxel_size = 3 * 128 / grid_size#3/2/2\n",
    "output.mkdir_safe(output_folder)\n",
    "volume_distribution = np.zeros(1)\n",
    "first_k = 1\n",
    "volume_distribution[:first_k] = 1/first_k\n",
    "\n",
    "image_stack, sim_info = simulator.generate_synthetic_dataset(output_folder, voxel_size, volume_folder_input, \n",
    "                                                             outlier_file_input, n_images, grid_size = grid_size,\n",
    "                               volume_distribution = volume_distribution,  dataset_params_option = \"dataset1\", noise_level =1e-8, \n",
    "                               noise_model = \"white\", put_extra_particles = False, percent_outliers = 0.0, \n",
    "                               volume_radius = 0.6, trailing_zero_format_in_vol_name = True, noise_scale_std = 0.2 * 0, contrast_std =0.1 * 0 , disc_type = 'nufft')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recovar2 [~/.conda/envs/recovar2/]",
   "language": "python",
   "name": "conda_recovar2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
